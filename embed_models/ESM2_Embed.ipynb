{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6e1Ufbg-LiC",
        "outputId": "240a4990-95af-403a-e457-75d050d872a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change into ProtClassify folder\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/ProtClassify')\n",
        "print(\"PWD:\", os.getcwd())\n",
        "# Should list all your notebooks, data/, combined_with_pfam.parquet, etc.\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYg6odRG-dJq",
        "outputId": "a7a81347-4489-4b25-aece-69adcc3fdb22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWD: /content/drive/MyDrive/ProtClassify\n",
            "total 63623\n",
            "-rw------- 1 root root   213993 Apr 17 23:27 Analysis_Preprocess_Assignment8.ipynb\n",
            "-rw------- 1 root root  3800496 Apr 21 21:16 combined_with_pfam.parquet\n",
            "-rw------- 1 root root   190991 Apr 24 15:58 Competition_Tuning_Assignment12.ipynb\n",
            "drwx------ 2 root root     4096 Apr 24 17:05 data\n",
            "drwx------ 2 root root     4096 Apr 24 17:05 docs\n",
            "drwx------ 2 root root     4096 Apr 24 17:05 ensemble_output\n",
            "drwx------ 2 root root     4096 Apr 24 17:05 external_tools\n",
            "-rw------- 1 root root   835872 Apr 21 06:38 feature_scores_combined.csv\n",
            "drwx------ 2 root root     4096 Apr 24 17:05 feature_selector\n",
            "-rw------- 1 root root      734 Apr 18 08:53 feature_selector_env.yaml\n",
            "-rw------- 1 root root   619649 Mar  9 21:57 metadata_org.csv\n",
            "-rw------- 1 root root  7191855 Apr  1 03:51 metadata_org_w_features.csv\n",
            "-rw------- 1 root root  1912656 Apr 22 04:09 Model_Eval_Assignment10.ipynb\n",
            "-rw------- 1 root root   716874 Apr 20 06:59 Model_Eval_Assignment9.ipynb\n",
            "-rw------- 1 root root     1194 Apr 22 03:46 model_results.csv\n",
            "-rw------- 1 root root  1409276 Apr 21 04:48 peptide_descriptors.csv\n",
            "-rw------- 1 root root 13736218 Apr 21 04:49 protlearn_features.csv\n",
            "-rw------- 1 root root   700544 Apr 24 15:16 pt5_eval.npy\n",
            "-rw------- 1 root root  2789504 Apr 24 15:16 pt5_train.npy\n",
            "drwx------ 2 root root     4096 Apr 24 17:05 __pycache__\n",
            "-rw------- 1 root root       32 Apr 23 08:05 README.md\n",
            "-rw------- 1 root root  1610612 Apr 24 04:46 test.csv\n",
            "-rw------- 1 root root  1769367 Apr 14 01:17 testing_data_w_features.csv\n",
            "-rw------- 1 root root  6539687 Apr 24 04:46 training.csv\n",
            "-rw------- 1 root root     1931 Apr 17 23:37 vhse_predictions.csv\n",
            "-rw------- 1 root root 21073762 Apr 21 04:49 X_all_features.csv\n",
            "-rw------- 1 root root     4881 Apr 21 04:49 y_all_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fair-esm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p751sIDJ_K_Q",
        "outputId": "81e4b803-472d-4c9c-d45f-7e5ccb6625a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── ESM2 Embedding Pipeline ─────────────────────────────────────────────\n",
        "import esm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Step 1: Load and clean sequences\n",
        "csv_path = \"metadata_org_w_features.csv\"\n",
        "output_file = \"esm2_train.npy\"\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "if \"CleanSequence\" not in df.columns:\n",
        "    raise ValueError(\"Missing 'CleanSequence' column in CSV\")\n",
        "\n",
        "df = df.drop_duplicates(subset=\"CleanSequence\").reset_index(drop=True)\n",
        "sequences = df[\"CleanSequence\"].tolist()\n",
        "\n",
        "print(f\"Loaded {len(sequences)} unique sequences\")\n",
        "\n",
        "# Step 2: Load ESM2 model and converter\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "model = model.to(device).eval()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "\n",
        "# Step 3: Embedding function\n",
        "def embed_esm2(seqs, batch_size=1):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(seqs), batch_size):\n",
        "        batch = [(str(j), seqs[j]) for j in range(i, min(i+batch_size, len(seqs)))]\n",
        "        labels, strs, toks = batch_converter(batch)\n",
        "        toks = toks.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            result = model(toks, repr_layers=[33], return_contacts=False)\n",
        "        token_reps = result[\"representations\"][33]\n",
        "        lengths = (toks != alphabet.padding_idx).sum(dim=1)\n",
        "\n",
        "        # Mean pool over tokens (excluding padding, start/end)\n",
        "        for j, length in enumerate(lengths):\n",
        "            vec = token_reps[j, 1:length-1].mean(0).cpu().numpy()\n",
        "            all_embeddings.append(vec)\n",
        "        torch.cuda.empty_cache()\n",
        "    return np.stack(all_embeddings)\n",
        "\n",
        "# Step 4: Run embeddings\n",
        "print(\"Embedding sequences with ESM2...\")\n",
        "embeddings = embed_esm2(sequences, batch_size=1)\n",
        "\n",
        "# Step 5: Verify output\n",
        "if len(set(map(tuple, embeddings[:5]))) == 1:\n",
        "    raise ValueError(\"Embeddings appear to be identical — investigate!\")\n",
        "\n",
        "print(\"Embedding shape:\", embeddings.shape)\n",
        "np.save(output_file, embeddings)\n",
        "print(f\"Saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpdxsCvb-gVw",
        "outputId": "f7b2f4fb-5d66-413d-ede6-b47adfd990ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 679 unique sequences\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding sequences with ESM2...\n",
            "Embedding shape: (679, 1280)\n",
            "Saved to esm2_train.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "esm2_train = np.load(\"esm2_train.npy\")\n",
        "print(\"Shape:\", esm2_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyiZHYawBvp0",
        "outputId": "efe3d6ff-f7c4-46f6-d315-920f8d9356ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (679, 1280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_rows = len(set(map(tuple, esm2_train[:5])))\n",
        "print(\"Unique rows among first 5:\", unique_rows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czEZkrPLCdXZ",
        "outputId": "69f60818-3bb0-430f-9b80-ac5ffaa1deb3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique rows among first 5: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First 5 sequences (first 10 dims):\")\n",
        "print(esm2_train[:5, :10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fin3rTC7CsTE",
        "outputId": "f24ab118-3f34-450e-d0af-1ca42ba3ab99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 sequences (first 10 dims):\n",
            "[[ 0.02434669 -0.05104493 -0.0653983   0.1614329  -0.08906472 -0.0185376\n",
            "   0.11717623  0.00490847 -0.02523768  0.11615728]\n",
            " [-0.03797659 -0.11156673 -0.02147814 -0.00271799  0.03247521 -0.04840764\n",
            "   0.07605141 -0.07524779 -0.05486202  0.04725526]\n",
            " [ 0.10650491 -0.07205261  0.003668    0.0389449  -0.03563187 -0.10197577\n",
            "   0.01765189 -0.08673552  0.0266648   0.05346079]\n",
            " [ 0.02212254 -0.03688725 -0.00731855  0.00818602 -0.03290962 -0.06052278\n",
            "   0.09439764  0.03983423  0.01361133  0.08567628]\n",
            " [ 0.01983873  0.02294585  0.04421835  0.10042888 -0.06179839 -0.0911576\n",
            "   0.07863367  0.0614925   0.0382542   0.07216165]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "\n",
        "dist = norm(esm2_train[0] - esm2_train[1])\n",
        "print(\"L2 distance between row 0 and 1:\", dist)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s-x8q0ACxbg",
        "outputId": "9e6ded38-2b54-4cc8-9ab8-635de00110e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 distance between row 0 and 1: 2.9229147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the test CSV\n",
        "test_csv = \"testing_data_w_features.csv\"\n",
        "output_file = \"esm2_eval.npy\"\n",
        "\n",
        "df_test = pd.read_csv(test_csv)\n",
        "if \"CleanSequence\" not in df_test.columns:\n",
        "    raise ValueError(\"Missing 'CleanSequence' column in test set.\")\n",
        "\n",
        "df_test = df_test.drop_duplicates(subset=\"CleanSequence\").reset_index(drop=True)\n",
        "test_sequences = df_test[\"CleanSequence\"].tolist()\n",
        "print(f\"Loaded {len(test_sequences)} unique test sequences\")\n",
        "\n",
        "# Step 2: Load ESM2 model and converter\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "model = model.to(device).eval()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "\n",
        "# Step 3: Embedding function\n",
        "def embed_esm2(seqs, batch_size=1):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(seqs), batch_size):\n",
        "        batch = [(str(j), seqs[j]) for j in range(i, min(i+batch_size, len(seqs)))]\n",
        "        labels, strs, toks = batch_converter(batch)\n",
        "        toks = toks.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            result = model(toks, repr_layers=[33], return_contacts=False)\n",
        "        token_reps = result[\"representations\"][33]\n",
        "        lengths = (toks != alphabet.padding_idx).sum(dim=1)\n",
        "\n",
        "        for j, length in enumerate(lengths):\n",
        "            vec = token_reps[j, 1:length-1].mean(0).cpu().numpy()\n",
        "            all_embeddings.append(vec)\n",
        "        torch.cuda.empty_cache()\n",
        "    return np.stack(all_embeddings)\n",
        "\n",
        "# Step 4: Run and save\n",
        "print(\"Embedding test sequences with ESM2...\")\n",
        "esm2_eval = embed_esm2(test_sequences, batch_size=1)\n",
        "\n",
        "print(\"Embedding shape:\", esm2_eval.shape)\n",
        "np.save(output_file, esm2_eval)\n",
        "print(f\"Saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBRu3jbrEJLd",
        "outputId": "790f1523-776f-4c08-c9b9-6f8b92ddf628"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 170 unique test sequences\n",
            "Using device: cuda\n",
            "Embedding test sequences with ESM2...\n",
            "Embedding shape: (170, 1280)\n",
            "Saved to esm2_eval.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ESM2 evaluation embeddings\n",
        "esm2_eval = np.load(\"esm2_eval.npy\")\n",
        "\n",
        "# Basic checks\n",
        "shape = esm2_eval.shape\n",
        "unique_rows = len(set(map(tuple, esm2_eval[:5])))\n",
        "\n",
        "# Show slice\n",
        "sample_df = pd.DataFrame(esm2_eval[:5, :10], columns=[f\"dim_{i}\" for i in range(10)])\n",
        "\n",
        "\n",
        "print(sample_df)\n",
        "print(\"Shape:\", shape)\n",
        "print(\"Unique rows among first 5:\", unique_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERW2jkSjDo5l",
        "outputId": "346e791a-c0ac-4c6e-9a70-703602ccea6d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      dim_0     dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n",
            "0 -0.055286 -0.069871 -0.017458  0.062318 -0.057167 -0.097157  0.046300   \n",
            "1 -0.031671 -0.013571 -0.046220  0.021139 -0.049918 -0.059739  0.042705   \n",
            "2 -0.011763 -0.025749 -0.020235  0.151089 -0.050390 -0.115374  0.093277   \n",
            "3  0.020814 -0.041365 -0.012924  0.012874  0.031504 -0.058197  0.086905   \n",
            "4 -0.005824 -0.108517 -0.067089  0.153602 -0.095592  0.014355  0.191420   \n",
            "\n",
            "      dim_7     dim_8     dim_9  \n",
            "0 -0.142198 -0.004714 -0.025495  \n",
            "1 -0.110206 -0.051680  0.067385  \n",
            "2 -0.000147  0.016088  0.155641  \n",
            "3  0.103312  0.050065  0.095398  \n",
            "4  0.004750  0.014283  0.197335  \n",
            "Shape: (170, 1280)\n",
            "Unique rows among first 5: 5\n"
          ]
        }
      ]
    }
  ]
}