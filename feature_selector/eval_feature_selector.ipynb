{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bdd04d",
   "metadata": {},
   "source": [
    "# Automated Feature Selection Engine for Protein Classification\n",
    "\n",
    "This notebook implements selection framework for the testing data for protein classification. It integrates statistical evaluation, machine learning-based scoring, group interaction modeling, and interpretability analysis, with the objective of identifying an optimal, biologically meaningful subset of features.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Principle\n",
    "\n",
    "Feature selection is treated as a formal optimization problem. Each feature and descriptor group is evaluated based on its predictive value, redundancy, and synergistic interactions — using statistical criteria, cross-validated model performance, and graph-theoretic reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "### 1. Feature Matrix Construction\n",
    "\n",
    "Features are extracted from the following sources:\n",
    "- `peptides.py`: Physicochemical and QSAR descriptors (e.g., VHSE, Z-scales, Atchley, Kidera)\n",
    "- `protlearn`: Sequence-derived descriptors (AAC, CTD, autocorrelations, motif, pseudo-AA, QSO)\n",
    "- `testing_data_w_features.csv`: Dipeptide frequencies, reduced alphabets, basic properties\n",
    "\n",
    "Features are grouped into logical biological/chemical sets:\n",
    "- Examples: `\"VHSE\"`, `\"Z-scales\"`, `\"Dipeptides\"`, `\"CTD\"`, `\"Binary Profile\"`, `\"ProtFP\"`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b22057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Core Libraries ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# === Scikit-learn: Preprocessing, Models, Feature Selection, CV ===\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, mutual_info_classif, f_classif, RFE, VarianceThreshold\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, cross_val_score, GridSearchCV\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "# === Bio Feature Engineering ===\n",
    "import peptides\n",
    "from peptides import Peptide\n",
    "from protlearn.features import (\n",
    "    aac, aaindex1, ngram, entropy, motif, atc, binary,\n",
    "    cksaap, ctd, ctdc, ctdt, ctdd, moreau_broto, moran,\n",
    "    geary, paac, apaac, socn, qso\n",
    ")\n",
    "\n",
    "# === Advanced Feature Selection ===\n",
    "from skrebate import ReliefF\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# === Optimization, Interpretability, Dimensionality ===\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.decomposition import PCA\n",
    "import shap\n",
    "\n",
    "\n",
    "# === Visualization ===\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Progress Tracking ===\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm as tqdm_auto\n",
    "tqdm.pandas()\n",
    "\n",
    "# === Disable Warnings ===\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a31a17",
   "metadata": {},
   "source": [
    "## Step 1: Extraction of Precomputed Features from Input Table\n",
    "\n",
    "In this step, the precomputed features contained within the `metadata_org_w_features.csv` file were extracted and organized into biologically meaningful components. These features serve as foundational inputs for downstream descriptor generation and classification tasks.\n",
    "\n",
    "The extracted components include:\n",
    "\n",
    "- `Entry`, `ProteinClass`: Identifiers and class labels for each protein sequence  \n",
    "- `Selected_PDB`, `CleanSequence`: Structural metadata and cleaned amino acid sequences  \n",
    "- `SequenceLength`: The total number of residues present in each protein  \n",
    "- `freq`: 20-dimensional amino acid composition vectors  \n",
    "- `dipep`: 400-dimensional dipeptide frequency features capturing sequential residue pairs  \n",
    "- `red_freq`: Composition profiles based on a reduced amino acid alphabet  \n",
    "- `red_ngram`: N-gram patterns derived from reduced alphabets  \n",
    "- `prop`: Physicochemical properties derived using Biopython, including molecular weight, isoelectric point, instability index, and secondary structure propensities\n",
    "\n",
    "These components were parsed into modular dataframes and preserved for integration with additional feature extraction tools in subsequent steps. This structured approach enables alignment between raw data and advanced descriptor pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8852fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (171, 588)\n",
      "First few columns: ['Entry', 'CleanSequence', 'Selected_PDB', 'SequenceLength', 'A', 'C', 'D', 'E', 'F', 'G']\n",
      "\n",
      "Base AAC feature shape: (171, 20)\n",
      "Base property feature sample:\n",
      "    base_IsoelectricPoint  base_Aromaticity  base_InstabilityIndex  \\\n",
      "0               7.865610          0.059590              33.680642   \n",
      "1               5.223413          0.049521              28.408163   \n",
      "2               5.655275          0.090411              36.957014   \n",
      "\n",
      "   base_Flexibility  base_Helix  base_Sheet  base_Turn  base_Gravy  \n",
      "0          0.999017    0.323091    0.292365   0.384544    0.028026  \n",
      "1          1.001449    0.263578    0.332268   0.349840   -0.173163  \n",
      "2          1.000302    0.293151    0.265753   0.345205   -0.498630  \n"
     ]
    }
   ],
   "source": [
    "# === Step 1: Load and Parse Evaluation Metadata Table ===\n",
    "\n",
    "# Load evaluation CSV\n",
    "data = pd.read_csv(\"../testing_data_w_features.csv\")  # or adjust path as needed\n",
    "\n",
    "# Verify required columns\n",
    "assert \"CleanSequence\" in data.columns, \"Missing column: 'CleanSequence'\"\n",
    "\n",
    "# Preview structure\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(\"First few columns:\", list(data.columns[:10]))\n",
    "\n",
    "# (DO NOT try to print Label distribution, evaluation set has no labels)\n",
    "\n",
    "# Metadata extraction\n",
    "metadata_cols = [\"Entry\", \"Selected_PDB\", \"CleanSequence\", \"SequenceLength\"]\n",
    "metadata_df = data[metadata_cols].copy()\n",
    "\n",
    "# === Step 1.1: Slice and Prefix Basic Feature Blocks ===\n",
    "\n",
    "# Define slicing schema\n",
    "i_start = 5  # After metadata columns\n",
    "\n",
    "# Amino acid composition\n",
    "freq = data.iloc[:, i_start : i_start + 20]\n",
    "freq.columns = [f\"base_{col}\" for col in freq.columns]  # fixed to 'base_'\n",
    "\n",
    "# Dipeptide frequencies\n",
    "i_start += 20\n",
    "dipep = data.iloc[:, i_start : i_start + 400]\n",
    "dipep.columns = [f\"base_{col}\" for col in dipep.columns]  # fixed to 'base_'\n",
    "\n",
    "# Reduced alphabet frequency\n",
    "i_start += 400\n",
    "red_freq = data.iloc[:, i_start : i_start + 5]\n",
    "red_freq.columns = [f\"base_{col}\" for col in red_freq.columns]  # fixed to 'base_'\n",
    "\n",
    "# Reduced alphabet N-grams\n",
    "i_start += 5\n",
    "red_ngram = data.iloc[:, i_start : i_start + 150]\n",
    "red_ngram.columns = [f\"base_{col}\" for col in red_ngram.columns]  # fixed to 'base_'\n",
    "\n",
    "# Physicochemical properties (Biopython features)\n",
    "i_start += 150\n",
    "prop = data.iloc[:, i_start:]\n",
    "prop.columns = [f\"base_{col}\" for col in prop.columns]  # fixed to 'base_'\n",
    "\n",
    "# === Step 1.2: Sanity Checks ===\n",
    "\n",
    "assert freq.shape[1] == 20, \"Expected 20 AAC features\"\n",
    "assert dipep.shape[1] == 400, \"Expected 400 dipeptide features\"\n",
    "assert red_freq.shape[1] == 5, \"Expected 5 reduced alphabet frequency features\"\n",
    "assert red_ngram.shape[1] == 150, \"Expected 150 reduced alphabet ngram features\"\n",
    "assert not prop.isnull().any().any(), \"Missing values detected in property descriptors\"\n",
    "\n",
    "# === Step 1.3: Preview ===\n",
    "\n",
    "print(\"\\nBase AAC feature shape:\", freq.shape)\n",
    "print(\"Base property feature sample:\\n\", prop.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2810dc",
   "metadata": {},
   "source": [
    "## Step 2: Generation of Peptide Descriptors (`peptides.py`)\n",
    "\n",
    "In this step, an extended set of **physicochemical and QSAR-inspired descriptors** was generated for each protein sequence using the `peptides.py` library. The `Peptide.descriptors()` method was employed to compute a **102-dimensional feature vector** that numerically summarizes key chemical and structural characteristics of each input sequence.\n",
    "\n",
    "The descriptors span the following categories:\n",
    "\n",
    "- **Amino Acid Factor Scores**  \n",
    "  - VHSE: Principal components derived from hydrophobic, electronic, and steric properties  \n",
    "  - Atchley Factors: Principal components summarizing amino acid physicochemical attributes  \n",
    "  - Kidera Factors: Orthogonal scores reflecting structural and physicochemical diversity\n",
    "\n",
    "- **Substitution Matrix Projections**  \n",
    "  - BLOSUM1–10: Numerical encodings of evolutionary similarity and substitution patterns\n",
    "\n",
    "- **Physicochemical Fingerprints and Indices**  \n",
    "  - Includes ProtFP, PCP, Z-Scales, ST-Scales, MS-WHIM scores  \n",
    "  - Sneath vectors were also computed, summarizing amino acid similarities in functional space\n",
    "\n",
    "- **Global Biochemical Properties**  \n",
    "  - Hydrophobicity, polarity, charge, spatial configuration, and other scalar indices\n",
    "\n",
    "---\n",
    "\n",
    "### Naming Convention\n",
    "\n",
    "All descriptors were systematically **prefixed with `Pep_`** to ensure clear modularity and traceability during downstream analysis. For example: `Pep_VHSE1`, `Pep_Kidera3`, and `Pep_BLOSUM7`. This convention facilitates descriptor group filtering, block-wise feature selection, and structured interpretability analyses.\n",
    "\n",
    "---\n",
    "\n",
    "### Rationale\n",
    "\n",
    "These descriptors provide **global, alignment-independent representations** of peptide sequences and are particularly valuable for capturing overarching chemical signatures. When integrated with localized sequence patterns and structural features (e.g., those computed in Step 3), this hybrid representation enables **robust, interpretable classification models** that generalize across protein families and functional classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7263b27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:01<00:00, 95.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peptide descriptor evaluation matrix shape: (171, 103)\n",
      "Example descriptors: ['Entry', 'PEP_AF1', 'PEP_AF2', 'PEP_AF3', 'PEP_AF4', 'PEP_AF5', 'PEP_BLOSUM1', 'PEP_BLOSUM2', 'PEP_BLOSUM3', 'PEP_BLOSUM4']\n"
     ]
    }
   ],
   "source": [
    "from peptides import Peptide\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# === Generate peptide descriptors for each sequence ===\n",
    "\n",
    "def compute_peptides_descriptors(seq: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generate a dictionary of peptide descriptors for a given protein sequence.\n",
    "\n",
    "    Parameters:\n",
    "    - seq (str): A string representation of a clean protein sequence.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing 102 physicochemical and QSAR-based descriptors\n",
    "            as computed by peptides.Peptide.descriptors().\n",
    "    \"\"\"\n",
    "    p = Peptide(seq)\n",
    "    return p.descriptors()\n",
    "\n",
    "# Apply the descriptor function to each sequence\n",
    "peptide_features_df = data['CleanSequence'].progress_apply(compute_peptides_descriptors)\n",
    "\n",
    "# Convert list of dictionaries into a structured DataFrame\n",
    "peptide_features_df = pd.DataFrame(peptide_features_df.tolist())\n",
    "\n",
    "# Fill any NaNs arising from invalid characters\n",
    "peptide_features_df = peptide_features_df.fillna(0)\n",
    "\n",
    "# Prefix all columns with 'PEP_'\n",
    "peptide_features_df.columns = [f\"PEP_{col}\" for col in peptide_features_df.columns]\n",
    "\n",
    "# Insert 'Entry' column for clean future merging\n",
    "peptide_features_df.insert(0, \"Entry\", data[\"Entry\"].values)\n",
    "\n",
    "# Save one folder up\n",
    "peptide_features_df.to_csv(\"../peptide_eval_descriptors.csv\", index=False)\n",
    "\n",
    "# Preview\n",
    "print(\"Peptide descriptor evaluation matrix shape:\", peptide_features_df.shape)\n",
    "print(\"Example descriptors:\", peptide_features_df.columns[:10].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f9d38",
   "metadata": {},
   "source": [
    "## Step 3: ProtLearn Feature Extraction\n",
    "\n",
    "In this step, a comprehensive suite of protein sequence descriptors was computed using the `protlearn` library. These descriptors were derived from physicochemical attributes, sequence order information, motif structure, autocorrelation functions, and compositional profiles.\n",
    "\n",
    "The extracted ProtLearn features were grouped into descriptor families, including:\n",
    "\n",
    "- **Amino Acid Composition (AAC):** Frequency of each amino acid observed in the sequence.  \n",
    "- **AAIndex1 Properties:** Averaged values across 553 numeric physicochemical indices.  \n",
    "- **Dipeptide N-Grams:** Frequencies of adjacent amino acid pairings.  \n",
    "- **Shannon Entropy:** An information-theoretic measure of intra-sequence variability.  \n",
    "- **Motif Presence:** Binary indicators of user-defined motifs (e.g., `AAx[KC]`).  \n",
    "- **ATC Descriptors:** Atomic and bond composition counts for C, H, N, O, S atoms.  \n",
    "- **Binary Profile:** One-hot encoded identity vectors for residue positions.  \n",
    "- **CKSAAP:** Composition of amino acid pairs separated by k residues (k=1 by default).  \n",
    "- **CTD Family:**\n",
    "  - CTD: Conjoint triad-based sequence groupings\n",
    "  - CTDC: Composition features\n",
    "  - CTDT: Transition metrics\n",
    "  - CTDD: Distribution profiles  \n",
    "- **Autocorrelations:**\n",
    "  - Moreau-Broto autocorrelation\n",
    "  - Moran's I spatial autocorrelation\n",
    "  - Geary’s C sequence dispersion  \n",
    "- **Pseudo Amino Acid Compositions (PseAAC):**\n",
    "  - PAAC: Encodes sequence order with physicochemical attributes\n",
    "  - APAAC: Adds amphiphilic hydrophobic/hydrophilic bias to PAAC  \n",
    "- **Sequence Order Descriptors:**\n",
    "  - SOCN: Sequence-order-coupling numbers (Schneider-Wrede and Grantham distances)\n",
    "  - QSO: Quasi-sequence-order descriptors using pairwise residue distances\n",
    "\n",
    "All features were concatenated into a unified `protlearn_df` matrix and integrated into the master dataset. Column names were prefixed with `PL_` to facilitate downstream identification and modular group tracking during block-wise optimization.\n",
    "\n",
    "This stage enabled rich encoding of structural, chemical, and spatial sequence properties without requiring homology alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6fc8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtLearn evaluation feature shape: (171, 1705)\n",
      "Example ProtLearn features: ['Entry', 'PL_AAIndex1_0', 'PL_AAIndex1_1', 'PL_AAIndex1_2', 'PL_AAIndex1_3', 'PL_AAIndex1_4', 'PL_AAIndex1_5', 'PL_AAIndex1_6', 'PL_AAIndex1_7', 'PL_AAIndex1_8']\n"
     ]
    }
   ],
   "source": [
    "# === Step 3: ProtLearn Feature Extraction for Evaluation ===\n",
    "\n",
    "from protlearn.features import (\n",
    "    aaindex1, entropy, motif, atc, cksaap, ctd, ctdc, ctdt, ctdd,\n",
    "    moreau_broto, moran, geary, paac, apaac, socn, qso\n",
    ")\n",
    "\n",
    "# Define ProtLearn feature computation function\n",
    "def compute_protlearn_features(seqs: list[str]) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Computes a suite of ProtLearn-derived protein sequence descriptors.\n",
    "\n",
    "    The extracted features cover:\n",
    "        - Physicochemical properties (e.g., AAIndex1, entropy, autocorrelation)\n",
    "        - Motif and compositional patterns (e.g., CTD, ATC)\n",
    "        - Order-dependent encodings (e.g., SOCN, QSO)\n",
    "        - Pseudo amino acid compositions (PAAC, APAAC)\n",
    "\n",
    "    Parameters:\n",
    "        seqs (list[str]): A list of amino acid sequences.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, pd.DataFrame]: A dictionary of feature blocks, each with its descriptor name as key.\n",
    "    \"\"\"\n",
    "    blocks = {}\n",
    "\n",
    "    # Physicochemical property summaries\n",
    "    blocks[\"AAIndex1\"], _ = aaindex1(seqs)\n",
    "\n",
    "    # Information-theoretic sequence entropy\n",
    "    blocks[\"Entropy\"] = entropy(seqs)\n",
    "\n",
    "    # Motif pattern presence\n",
    "    blocks[\"Motif\"] = motif(seqs, pattern=\"AAx[KC]\")\n",
    "\n",
    "    # Atom and bond composition\n",
    "    blocks[\"ATC_atoms\"], blocks[\"ATC_bonds\"] = atc(seqs)\n",
    "\n",
    "    # K-spaced amino acid pairs\n",
    "    blocks[\"CKSAAP\"], _ = cksaap(seqs, k=1)\n",
    "\n",
    "    # CTD (composition, transition, distribution)\n",
    "    blocks[\"CTD\"], _ = ctd(seqs)\n",
    "    blocks[\"CTDC\"], _ = ctdc(seqs)\n",
    "    blocks[\"CTDT\"], _ = ctdt(seqs)\n",
    "    blocks[\"CTDD\"], _ = ctdd(seqs)\n",
    "\n",
    "    # Spatial autocorrelations\n",
    "    blocks[\"MoreauBroto\"] = moreau_broto(seqs)\n",
    "    blocks[\"Moran\"] = moran(seqs)\n",
    "    blocks[\"Geary\"] = geary(seqs)\n",
    "\n",
    "    # Pseudo amino acid compositions\n",
    "    blocks[\"PAAC\"], _ = paac(seqs, lambda_=3)\n",
    "    blocks[\"APAAC\"], _ = apaac(seqs, lambda_=3)\n",
    "\n",
    "    # Order-coupling descriptors\n",
    "    blocks[\"SOCN_SW\"], blocks[\"SOCN_Grantham\"] = socn(seqs, d=3)\n",
    "    blocks[\"QSO_SW\"], blocks[\"QSO_Grantham\"], _ = qso(seqs, d=3)\n",
    "\n",
    "    return blocks\n",
    "\n",
    "# Extract sequences from the evaluation dataset\n",
    "seqs_eval: list[str] = data[\"CleanSequence\"].tolist()\n",
    "\n",
    "# Apply ProtLearn feature extraction\n",
    "protlearn_blocks_eval = compute_protlearn_features(seqs_eval)\n",
    "\n",
    "# Format blocks with descriptor-specific prefixes\n",
    "named_blocks_eval = []\n",
    "for block_name, block_df in protlearn_blocks_eval.items():\n",
    "    df_block = pd.DataFrame(block_df)\n",
    "    df_block.columns = [f\"PL_{block_name}_{col}\" for col in df_block.columns]\n",
    "    named_blocks_eval.append(df_block)\n",
    "\n",
    "# Concatenate all formatted blocks into a unified DataFrame\n",
    "protlearn_eval_df = pd.concat(named_blocks_eval, axis=1)\n",
    "\n",
    "# Insert Entry column for future clean merging\n",
    "protlearn_eval_df.insert(0, \"Entry\", data[\"Entry\"].values)\n",
    "\n",
    "# Save ProtLearn features for evaluation one folder up\n",
    "protlearn_eval_df.to_csv(\"../protlearn_eval_features.csv\", index=False)\n",
    "\n",
    "# Preview confirmation\n",
    "print(f\"ProtLearn evaluation feature shape: {protlearn_eval_df.shape}\")\n",
    "print(\"Example ProtLearn features:\", protlearn_eval_df.columns[:10].tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature_selector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
